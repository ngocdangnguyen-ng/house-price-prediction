{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efe77eec",
   "metadata": {},
   "source": [
    "# Model Evaluation - House Price Dataset\n",
    "## Introduction\n",
    "This notebook performs **model evaluation** for the house price prediction project. It assesses the performance of the trained models using various metrics, cross-validation, and residual analysis, and provides visualizations to interpret the results.\n",
    "\n",
    "**Dataset:** Housing Price Prediction Data (Kaggle)\n",
    "\n",
    "**Objective:** Evaluate the predictive performance of the final models and interpret their results.\n",
    "\n",
    "**Author:** NGUYEN Ngoc Dang Nguyen - Final-year Student in Computer Science, Aix-Marseille University\n",
    "\n",
    "**Evaluation steps:**\n",
    "1. Import libraries and load processed data and models\n",
    "2. Prepare data for evaluation\n",
    "3. Evaluate model performance using regression metrics\n",
    "4. Perform cross-validation analysis\n",
    "5. Analyze residuals\n",
    "6. Visualize evaluation results\n",
    "7. Summarize findings and next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d839ef9",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbe0c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "df = pd.read_csv('../data/processed/engineered_data.csv')\n",
    "print('Columns in engineered_data.csv:', list(df.columns))\n",
    "# Try to infer the target column\n",
    "possible_targets = [col for col in df.columns if 'price' in col.lower()]\n",
    "if possible_targets:\n",
    "    target_col = possible_targets[0]\n",
    "    print(f\"Using '{target_col}' as the target column.\")\n",
    "else:\n",
    "    raise KeyError('No column containing \"price\" found in engineered_data.csv. Please check your data.')\n",
    "features_list = [col for col in df.columns if col != target_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f90277e",
   "metadata": {},
   "source": [
    "## 2. Load the Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc4a6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = '../models/'\n",
    "best_model_file = [f for f in os.listdir(models_dir) if 'best_model' in f][0]\n",
    "best_model = joblib.load(os.path.join(models_dir, best_model_file))\n",
    "print(f\"Loaded best model: {best_model_file}\")\n",
    "\n",
    "# Get model's feature names if available\n",
    "model_features = None\n",
    "if hasattr(best_model, 'feature_names_in_'):\n",
    "    model_features = list(best_model.feature_names_in_)\n",
    "    print('Model was trained with features:', model_features)\n",
    "else:\n",
    "    print('Model does not have feature_names_in_ attribute. Using all features from data.')\n",
    "\n",
    "# Use only the intersection of features for prediction\n",
    "data_features = features_list\n",
    "if model_features is not None:\n",
    "    used_features = [f for f in model_features if f in data_features]\n",
    "    missing_in_data = [f for f in model_features if f not in data_features]\n",
    "    extra_in_data = [f for f in data_features if f not in model_features]\n",
    "    print('Features used for prediction:', used_features)\n",
    "    if missing_in_data:\n",
    "        print('Warning: These features were in the model but not in the data:', missing_in_data)\n",
    "    if extra_in_data:\n",
    "        print('Note: These features are in the data but not in the model:', extra_in_data)\n",
    "else:\n",
    "    used_features = data_features\n",
    "\n",
    "X = df[used_features]\n",
    "y = df[target_col]\n",
    "print(f\"Final features used: {used_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea54e74",
   "metadata": {},
   "source": [
    "## 3. Evaluate Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e222e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Split data (train/val/test, same as model development)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)\n",
    "print(f\"Train set: {X_train.shape}, Validation set: {X_val.shape}, Test set: {X_test.shape}\")\n",
    "\n",
    "# 5. Evaluate model performance with metrics\n",
    "def regression_metrics(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return {'MSE': mse, 'RMSE': rmse, 'MAE': mae, 'R2': r2}\n",
    "\n",
    "results = {}\n",
    "for split, X_, y_ in zip(['Train', 'Validation', 'Test'], [X_train, X_val, X_test], [y_train, y_val, y_test]):\n",
    "    y_pred = best_model.predict(X_)\n",
    "    results[split] = regression_metrics(y_, y_pred)\n",
    "    print(f\"{split} set:\")\n",
    "    for k, v in results[split].items():\n",
    "        print(f\"  {k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23cbc48",
   "metadata": {},
   "source": [
    "## 4. Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e30b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(best_model, X_train, y_train, cv=5, scoring='neg_root_mean_squared_error')\n",
    "print(f\"\\n5-Fold CV RMSE: {-cv_scores.mean():.4f} Â± {cv_scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da00952a",
   "metadata": {},
   "source": [
    "## 5. Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f0a368",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = best_model.predict(X_test)\n",
    "residuals = y_test - y_test_pred\n",
    "plt.figure()\n",
    "sns.histplot(residuals, kde=True)\n",
    "plt.title('Residuals Distribution (Test Set)')\n",
    "plt.xlabel('Residual')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(y_test_pred, residuals, alpha=0.6)\n",
    "plt.axhline(0, color='red', linestyle='--')\n",
    "plt.title('Residuals vs. Predicted (Test Set)')\n",
    "plt.xlabel('Predicted SalePrice')\n",
    "plt.ylabel('Residual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71342843",
   "metadata": {},
   "source": [
    "## 6. Summarize Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fc175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSummary:\")\n",
    "print(f\"Best model: {best_model_file}\")\n",
    "print(f\"Test RMSE: {results['Test']['RMSE']:.4f}\")\n",
    "print(f\"Test R2: {results['Test']['R2']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2325a483",
   "metadata": {},
   "source": [
    "## Model Evaluation Summary & Next Steps\n",
    "The evaluation process provided a thorough assessment of the final model's predictive performance using multiple metrics, cross-validation, and residual analysis. The results confirm the model's strengths and highlight areas for further improvement. With these insights, the project is ready for deployment and real-world application, or for further refinement if desired."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
