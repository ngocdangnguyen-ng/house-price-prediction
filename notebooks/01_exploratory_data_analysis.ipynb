{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e62b3eff",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis - House Price Dataset\n",
    "## Introduction\n",
    "This notebook presents an **exploratory data analysis (EDA)** of a residential housing dataset from Kaggle, as part of a personal machine learning project. The goal of this analysis is to identify key factors that influence house prices and to prepare the dataset for further predictive modeling.\n",
    "\n",
    "**Dataset:** Housing Price Prediction Data (Kaggle)\n",
    "\n",
    "**Objective:** Explore and visualize the dataset to gain insights and guide further analysis.\n",
    "\n",
    "**Author:** NGUYEN Ngoc Dang Nguyen - Final-year Student in Computer Science, Aix-Marseille University\n",
    "\n",
    "**EDA steps:** \n",
    "1. Load and preview the raw dataset\n",
    "2. Assess dataset structure and data types\n",
    "3. Analyze missing values and data quality\n",
    "4. Explore the target variable distribution\n",
    "5. Analyze categorical and numerical features\n",
    "6. Investigate feature relationships and correlations\n",
    "7. Detect and visualize outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a46dc1",
   "metadata": {},
   "source": [
    "## 1. Load Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e66816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Set style for plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(r\"c:\\Users\\nndng\\OneDrive\\Desktop\\house-price-prediction\\house-price-prediction\\data\\raw\\housing_price_dataset.csv\")\n",
    "df.columns = df.columns.str.strip() \n",
    "\n",
    "print(f\"Dataset loaded: {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a6fe86",
   "metadata": {},
   "source": [
    "## 2. Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b702b339",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset Overview\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Number of houses: {len(df)}\")\n",
    "print(f\"Number of features: {len(df.columns)}\")\n",
    "print(f\"Dataset size: {df.memory_usage(deep=True).sum() / 1024:.1f} KB\")\n",
    "\n",
    "print(\"\\nColumn names:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i:2d}. {col}\")\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nQuick statistics:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e11f655",
   "metadata": {},
   "source": [
    "## 3. Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7361cb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Checking for missing values...\")\n",
    "missing = df.isnull().sum()\n",
    "if missing.sum() > 0:\n",
    "    missing_df = pd.DataFrame({\n",
    "        'Column': missing.index,\n",
    "        'Missing Count': missing.values,\n",
    "        'Percentage': (missing.values / len(df) * 100).round(1)\n",
    "    })\n",
    "    missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
    "    \n",
    "    print(f\"Found {len(missing_df)} columns with missing values:\")\n",
    "    print(missing_df.to_string(index=False))\n",
    "    \n",
    "    # Simple visualization\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.barplot(data=missing_df, x='Percentage', y='Column')\n",
    "    plt.title('Missing Values by Column')\n",
    "    plt.xlabel('Percentage Missing (%)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No missing values found in the dataset!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc576bf1",
   "metadata": {},
   "source": [
    "## 4. Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9be06c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the price column - could be 'price', 'price_per_m2', etc.\n",
    "price_cols = [col for col in df.columns if 'price' in col.lower()]\n",
    "if not price_cols:\n",
    "    # Try other common names\n",
    "    price_cols = [col for col in df.columns if col.lower() in ['cost', 'value', 'amount']]\n",
    "\n",
    "if price_cols:\n",
    "    price_col = price_cols[0]  # Use first price column found\n",
    "else:\n",
    "    # Use first numeric column as fallback\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    price_col = numeric_cols[0]\n",
    "\n",
    "print(f\"Analyzing target variable: {price_col}\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Basic stats\n",
    "print(f\"Average price: {df[price_col].mean():.2f}\")\n",
    "print(f\"Median price: {df[price_col].median():.2f}\")\n",
    "print(f\"Price range: {df[price_col].min():.2f} to {df[price_col].max():.2f}\")\n",
    "print(f\"Standard deviation: {df[price_col].std():.2f}\")\n",
    "\n",
    "# Visualize price distribution\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(df[price_col], bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "plt.title(f'Distribution of {price_col}')\n",
    "plt.xlabel(price_col)\n",
    "plt.ylabel('Count')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.boxplot(df[price_col])\n",
    "plt.title('Price Box Plot')\n",
    "plt.ylabel(price_col)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(df[price_col], bins=30, alpha=0.7, color='lightgreen', edgecolor='black')\n",
    "plt.title('Price Distribution (Zoomed)')\n",
    "# Remove extreme outliers for better view\n",
    "q99 = df[price_col].quantile(0.99)\n",
    "plt.xlim(0, q99)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5fca02",
   "metadata": {},
   "source": [
    "## 5. Categorical Variables Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688c58a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "if categorical_cols:\n",
    "    print(\"Categorical Features Analysis\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    for col in categorical_cols[:4]:  # Analyze first 4 categorical columns\n",
    "        print(f\"\\n{col}:\")\n",
    "        value_counts = df[col].value_counts()\n",
    "        print(f\"  * {df[col].nunique()} unique values\")\n",
    "        print(f\"  * Most common: {value_counts.index[0]} ({value_counts.iloc[0]} times)\")\n",
    "        \n",
    "        # Show distribution\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        top_values = value_counts.head(8)  # Show top 8 categories\n",
    "        plt.bar(range(len(top_values)), top_values.values)\n",
    "        plt.xticks(range(len(top_values)), top_values.index, rotation=45)\n",
    "        plt.title(f'Distribution of {col}')\n",
    "        plt.ylabel('Count')\n",
    "        \n",
    "        # Box plot if not too many categories\n",
    "        if df[col].nunique() <= 10:\n",
    "            plt.subplot(1, 2, 2)\n",
    "            sns.boxplot(x=col, y=price_col, data=df)\n",
    "            plt.title(f'{price_col} by {col}')\n",
    "            plt.xticks(rotation=45)\n",
    "        else:\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.text(0.5, 0.5, f'Too many categories\\n({df[col].nunique()} unique values)', \n",
    "                     ha='center', va='center', transform=plt.gca().transAxes, fontsize=12)\n",
    "            plt.title('Too many categories for box plot')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"No categorical columns found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267b6126",
   "metadata": {},
   "source": [
    "## 6. Numerical Variables Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c4265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find numerical columns (excluding our target)\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if price_col in numeric_cols:\n",
    "    numeric_cols.remove(price_col)\n",
    "\n",
    "print(f\"Numerical Features Analysis\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Found {len(numeric_cols)} numerical features:\")\n",
    "print(numeric_cols)\n",
    "\n",
    "if numeric_cols:\n",
    "    # Show basic stats\n",
    "    print(f\"\\nStatistics for numerical features:\")\n",
    "    print(df[numeric_cols].describe().round(2))\n",
    "    \n",
    "    # Plot distributions\n",
    "    n_features = min(6, len(numeric_cols))  # Show max 6 features\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, col in enumerate(numeric_cols[:n_features]):\n",
    "        axes[i].hist(df[col].dropna(), bins=20, alpha=0.7, color='lightcoral')\n",
    "        axes[i].set_title(f'Distribution of {col}')\n",
    "        axes[i].set_xlabel(col)\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "    \n",
    "    # Hide empty plots\n",
    "    for j in range(i+1, len(axes)):\n",
    "        axes[j].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf6031f",
   "metadata": {},
   "source": [
    "## 7. Relationships Between Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddba748",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature Relationships\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Calculate correlations for numerical features\n",
    "numeric_for_corr = [price_col] + numeric_cols\n",
    "if len(numeric_for_corr) > 1:\n",
    "    correlation_matrix = df[numeric_for_corr].corr()\n",
    "    \n",
    "    # Show correlations with price\n",
    "    price_correlations = correlation_matrix[price_col].drop(price_col).abs().sort_values(ascending=False)\n",
    "    \n",
    "    print(f\"Features most related to {price_col}:\")\n",
    "    for feature, corr in price_correlations.head(5).items():\n",
    "        print(f\"  * {feature}: {corr:.3f}\")\n",
    "    \n",
    "    # Correlation heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "    plt.title('Correlation Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Scatter plots of top correlated features\n",
    "    top_features = price_correlations.head(4).index.tolist()\n",
    "    if top_features:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, feature in enumerate(top_features):\n",
    "            axes[i].scatter(df[feature], df[price_col], alpha=0.5)\n",
    "            axes[i].set_xlabel(feature)\n",
    "            axes[i].set_ylabel(price_col)\n",
    "            axes[i].set_title(f'{price_col} vs {feature}')\n",
    "            \n",
    "            # Add simple trend line\n",
    "            z = np.polyfit(df[feature].dropna(), df[price_col].dropna(), 1)\n",
    "            p = np.poly1d(z)\n",
    "            axes[i].plot(df[feature], p(df[feature]), \"r--\", alpha=0.8)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a2ff74",
   "metadata": {},
   "source": [
    "## 8. Looking for Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bc49b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Outlier Detection\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Simple outlier detection using IQR method on price\n",
    "Q1 = df[price_col].quantile(0.25)\n",
    "Q3 = df[price_col].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "outliers = df[(df[price_col] < lower_bound) | (df[price_col] > upper_bound)]\n",
    "print(f\"Found {len(outliers)} potential outliers in {price_col}\")\n",
    "print(f\"That's {len(outliers)/len(df)*100:.1f}% of the data\")\n",
    "\n",
    "if len(outliers) > 0:\n",
    "    print(f\"Outlier price range: {outliers[price_col].min():.2f} to {outliers[price_col].max():.2f}\")\n",
    "    print(f\"Normal price range: {lower_bound:.2f} to {upper_bound:.2f}\")\n",
    "\n",
    "# Visualize outliers\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(range(len(df)), df[price_col], alpha=0.6, label='Normal')\n",
    "outlier_indices = df[(df[price_col] < lower_bound) | (df[price_col] > upper_bound)].index\n",
    "plt.scatter(outlier_indices, df.loc[outlier_indices, price_col], color='red', alpha=0.8, label='Outliers')\n",
    "plt.xlabel('House Index')\n",
    "plt.ylabel(price_col)\n",
    "plt.title('Houses with Outlier Prices')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(df[price_col])\n",
    "plt.title(f'{price_col} Box Plot')\n",
    "plt.ylabel(price_col)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c0f36a",
   "metadata": {},
   "source": [
    "## Exploratory Analysis Conclusion\n",
    "The exploratory data analysis provided a comprehensive understanding of the dataset's structure, distributions, and key relationships. By visualizing missing values, outliers, and feature correlations, we identified the most influential variables and potential data quality issues. These insights form a solid foundation for effective data cleaning, feature engineering, and model development in the subsequent steps of the pipeline."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
